{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Create test dataloader\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Move model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Store predictions and labels\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "test_texts = []\n",
        "\n",
        "# Prediction loop\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        pred_labels.extend(predictions.cpu().numpy())\n",
        "\n",
        "        if 'text' in batch:\n",
        "            test_texts.extend(batch['text'])  # Use original text if available\n",
        "        else:\n",
        "            test_texts.extend([\"[Text not available]\"] * len(labels))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "label_names = ['Negative (0)', 'Neutral (1)', 'Positive (2)']\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_names, yticklabels=label_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix - Sentiment Analysis')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, pred_labels, target_names=label_names))\n",
        "\n",
        "# Misclassified Examples\n",
        "misclassified = []\n",
        "for text, true, pred in zip(test_texts, true_labels, pred_labels):\n",
        "    if true != pred:\n",
        "        misclassified.append((text, true, pred))\n",
        "\n",
        "if misclassified:\n",
        "    print(\"\\nMisclassified Examples:\")\n",
        "    for i, (text, true, pred) in enumerate(misclassified[:5]):\n",
        "        print(f\"\\nExample {i+1}\")\n",
        "        print(f\"Text: {text}\")\n",
        "        print(f\"True Label: {true} → Predicted Label: {pred}\")\n",
        "        print(\"-\" * 50)\n",
        "else:\n",
        "    print(\"\\n✅ No misclassified examples found. Perfect accuracy on the test set.\")\n"
      ],
      "metadata": {
        "id": "5xF7VFeNjkvM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}